# CMU 16-726 Learning-Based Image Synthesis / Spring 2021, Assignment 3
#
# The code base is based on the great work from CSC 321, U Toronto
# https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip
# This is the main training file for the second part of the assignment.
#
# Usage:
# ======
#    To train with the default hyperparamters (saves results to samples_cyclegan/):
#       python cycle_gan.py
#
#    To train with cycle consistency loss (saves results to samples_cyclegan_cycle/):
#       python cycle_gan.py --use_cycle_consistency_loss
#
#
#    For optional experimentation:
#    -----------------------------
#    If you have a powerful computer (ideally with a GPU), then you can obtain better results by
#    increasing the number of filters used in the generator and/or discriminator, as follows:
#      python cycle_gan.py --g_conv_dim=64 --d_conv_dim=64

import argparse
import os
import warnings
import pdb
# Matplotlib
# import matplotlib
import matplotlib.pyplot as plt
# matplotlib.use("TkAgg")
import imageio
from torch.utils.tensorboard import SummaryWriter
warnings.filterwarnings("ignore")

# Torch imports
import torch
import torch.optim as optim

# Numpy & Scipy imports
import numpy as np

# Local imports
import utils
from data_loader import get_data_loader_test
from models_cycle_gan import CycleGeneratorMixer, CycleGeneratorViT, CycleGenerator, weights_init
from diff_aug import DiffAugment
SEED = 11

# Set the random seed manually for reproducibility.
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def print_models(G_XtoY, G_YtoX):
    """Prints model information for the generators and discriminators.
    """
    print("                 G_XtoY                ")
    print("---------------------------------------")
    print(G_XtoY)
    print("---------------------------------------")

    print("                 G_YtoX                ")
    print("---------------------------------------")
    print(G_YtoX)
    print("---------------------------------------")

def create_model(opts):
    """Builds the generators and discriminators.
    """
    model_dict = {'cycle': CycleGenerator,
                  'vit': CycleGeneratorViT,
                  'mix': CycleGeneratorMixer}

    if opts.gen == "cycle":
        G_XtoY = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights, norm=opts.norm)
        G_YtoX = CycleGenerator(conv_dim=opts.g_conv_dim, init_zero_weights=opts.init_zero_weights, norm=opts.norm)

    elif opts.gen == "vit":
        G_XtoY = CycleGeneratorViT(embed_dim=opts.g_conv_dim, patch_dim=opts.patch_dim, num_heads=8,
                                   transform_layers=opts.blocks, patch_size=opts.patch)
        G_YtoX = CycleGeneratorViT(embed_dim=opts.g_conv_dim, patch_dim=opts.patch_dim, num_heads=8,
                                   transform_layers=opts.blocks, patch_size=opts.patch)

    elif opts.gen == "mix":
        G_XtoY = CycleGeneratorMixer(embed_dim=opts.g_conv_dim, image_size=opts.image_size, patch_dim=opts.patch_dim,
                                     transform_layers=opts.blocks, patch_size=opts.patch)
        G_YtoX = CycleGeneratorMixer(embed_dim=opts.g_conv_dim, image_size=opts.image_size, patch_dim=opts.patch_dim,
                                     transform_layers=opts.blocks, patch_size=opts.patch)

    print_models(G_XtoY, G_YtoX)

    # todo: B&W add your own initialization here
    G_XtoY.apply(weights_init)
    G_YtoX.apply(weights_init)

    if torch.cuda.is_available():
        G_XtoY.cuda()
        G_YtoX.cuda()
        print('Models moved to GPU.')

    return G_XtoY, G_YtoX

def merge_images(sources, targets, opts, k=10):
    """Creates a grid consisting of pairs of columns, where the first column in
    each pair contains images source images and the second column in each pair
    contains images generated by the CycleGAN from the corresponding images in
    the first column.
    """
    _, _, h, w = sources.shape
    row = int(np.sqrt(opts.batch_size))
    merged = np.zeros([3, row * h, row * w * 2])
    for idx, (s, t) in enumerate(zip(sources, targets)):
        i = idx // row
        j = idx % row
        merged[:, i * h:(i + 1) * h, (j * 2) * h:(j * 2 + 1) * h] = s
        merged[:, i * h:(i + 1) * h, (j * 2 + 1) * h:(j * 2 + 2) * h] = t
    return merged.transpose(1, 2, 0)

def prep_individual(images):
    """Saves individual images"""
    images = images.squeeze()
    _, h, w = images.shape
    return images.transpose(1, 2, 0)

def save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, opts):
    """Saves samples from both generators X->Y and Y->X.
    """
    fake_X = G_YtoX(fixed_Y)
    fake_Y = G_XtoY(fixed_X)

    X, fake_X = utils.to_data(fixed_X), utils.to_data(fake_X)
    Y, fake_Y = utils.to_data(fixed_Y), utils.to_data(fake_Y)

    merged = merge_images(X, fake_Y, opts)
    logger.add_image("Fake_Y", img_tensor=(merged + 1) / 2, global_step=iteration, dataformats="HWC")
    path = os.path.join(opts.sample_dir, 'sample-{:06d}-X-Y.png'.format(iteration))
    imageio.imwrite(path, merged)
    print('Saved {}'.format(path))

    merged = merge_images(Y, fake_X, opts)
    logger.add_image("Fake_X", img_tensor=(merged + 1) / 2, global_step=iteration, dataformats="HWC")
    path = os.path.join(opts.sample_dir, 'sample-{:06d}-Y-X.png'.format(iteration))
    imageio.imwrite(path, merged)
    print('Saved {}'.format(path))

def save_samples2(iteration, fake, real, opts, XtoY=True):
    """Saves samples from both generators X->Y and Y->X.
    """
    real, fake = utils.to_data(real), utils.to_data(fake)
    if XtoY:
        name = 'XtoY'
        fake_dir = opts.x2y_dir
        real_dir = opts.reals_x_dir
        real_name = 'X'
    else:
        name = 'YtoX'
        fake_dir = opts.y2x_dir
        real_dir = opts.reals_y_dir
        real_name = 'Y'

    if opts.save_ind:
        # To save individual generated images without paired with real image
        merged = prep_individual(fake)
        reals = prep_individual(real)

        # Save all reals together
        path = os.path.join(opts.reals_dir, 'real-{:06d}-{}.png'.format(iteration, name))
        imageio.imwrite(path, reals)

        # Save all fakes together
        path = os.path.join(opts.sample_dir, 'sample-{:06d}-{}.png'.format(iteration, name))
        imageio.imwrite(path, merged)

        # Save domain-specific reals
        path_reals_domain = os.path.join(real_dir, 'sample-{:06d}-{}.png'.format(iteration, real_name))
        imageio.imwrite(path_reals_domain, reals)

        # Save domain-specific fakes
        path_fakes_domain = os.path.join(fake_dir, 'sample-{:06d}-{}.png'.format(iteration, name))
        imageio.imwrite(path_fakes_domain, merged)

        print('Saved All!')


    else:
        merged = merge_images(real, fake, opts)
        path = os.path.join(opts.sample_dir, 'sample-{:06d}-{}.png'.format(iteration, name))
        imageio.imwrite(path, merged)
        print('Saved {}'.format(path))

def testing_loop(dataloader_X, dataloader_Y, opts):
    """Runs the training loop.
        * Saves checkpoint every opts.checkpoint_every iterations
        * Saves generated samples every opts.sample_every iterations
    """
    # Create generators and discriminators
    G_XtoY, G_YtoX = create_model(opts)
    # print('\n=========== PARAMS =================')
    # for name, param in G_XtoY.named_parameters():
    #     print('name: ', name)
    #     print('param: ', param.shape)

    # Load generators, TODO: optimize this pipeline
    G_XtoY.load_state_dict(torch.load(opts.load_G_XtoY))
    G_YtoX.load_state_dict(torch.load(opts.load_G_YtoX))

    G_XtoY.eval()
    G_YtoX.eval()
    # Get some fixed data from domains X and Y for sampling. These are images that are held
    # constant throughout training, that allow us to inspect the model's performance.
    iter_X = iter(dataloader_X)
    iter_Y = iter(dataloader_Y)

    iter_per_epoch = min(len(iter_X), len(iter_Y))

    print('len dataloader X: ', len(dataloader_X))
    print('len dataloader Y: ', len(dataloader_Y))
    print('iter X len: ', len(iter_X))
    print('iter Y len: ', len(iter_Y))
    print('iter_per_epoch: ', iter_per_epoch)
    print('iter X: ', iter_X)
    with torch.no_grad():

        for iteration, (images_X, _) in enumerate(dataloader_X):
            images_X = utils.to_var(images_X)
            fake_Y = G_XtoY(images_X)
            save_samples2(iteration, fake_Y, images_X, opts, XtoY=True)

        for iteration, (images_Y, _) in enumerate(dataloader_Y):
            images_Y = utils.to_var(images_Y)
            fake_X = G_YtoX(images_Y)
            save_samples2(iteration, fake_X, images_Y, opts, XtoY=False)

def main(opts):
    """Loads the data, creates checkpoint and sample directories, and starts the training loop.
    """
    # Create  dataloaders for images from the two domains X and Y
    dataloader_X = get_data_loader_test(opts.X, opts=opts)
    dataloader_Y = get_data_loader_test(opts.Y, opts=opts)
    print('dataloaders created')
    print('lengh of dataloader X: ', len(dataloader_X))
    print('lengh of dataloader Y: ', len(dataloader_Y))

    # Create checkpoint and sample directories
    utils.create_dir(opts.sample_dir)
    utils.create_dir(opts.reals_dir)

    utils.create_dir(opts.x2y_dir)
    utils.create_dir(opts.y2x_dir)
    utils.create_dir(opts.reals_x_dir)
    utils.create_dir(opts.reals_y_dir)

    # Start training
    testing_loop(dataloader_X, dataloader_Y, opts)

def print_opts(opts):
    """Prints the values of all command-line arguments.
    """
    print('=' * 80)
    print('Opts'.center(80))
    print('-' * 80)
    for key in opts.__dict__:
        if opts.__dict__[key]:
            print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))
    print('=' * 80)

def create_parser():
    """Creates a parser for command-line arguments.
    """
    parser = argparse.ArgumentParser()

    # Model hyper-parameters
    parser.add_argument('--image_size', type=int, default=128, help='The side length N to convert images to NxN.')
    parser.add_argument('--gen', type=str, default='mix')
    parser.add_argument('--g_conv_dim', type=int, default=512)
    parser.add_argument('--norm', type=str, default='instance')
    parser.add_argument('--use_cycle_consistency_loss', action='store_true', default=True,
                        help='Choose whether to include the cycle consistency term in the loss.')
    parser.add_argument('--init_zero_weights', action='store_true', default=False,
                        help='Choose whether to initialize the generator conv weights to 0 (implements the identity function).')
    parser.add_argument('--init_type', type=str, default='naive')

    # Training hyper-parameters
    parser.add_argument('--batch_size', type=int, default=1, help='The number of images in a batch.')
    parser.add_argument('--num_workers', type=int, default=0, help='The number of threads to use for the DataLoader.')

    # Data sources
    parser.add_argument('--X', type=str, default='/home/manuelladron/datasets/BestCycleGAN/Horse/Real',
                        help='Choose the type of images for domain X.')
    parser.add_argument('--Y', type=str, default='/home/manuelladron/datasets/BestCycleGAN/Zebra/Real',
                        help='Choose the type of images for domain Y.')
    # parser.add_argument('--X', type=str, default='/home/manuelladron/datasets/people.eecs.berkeley.edu/~taesung_park'
    #                                              '/CycleGAN/datasets/horse2zebra/testA', help='Choose the '
    #                                                                                                    'type of '
    #                                                                                            'images for domain X.')
    # parser.add_argument('--Y', type=str, default='/home/manuelladron/datasets/people.eecs.berkeley.edu/~taesung_park'
    #                                              '/CycleGAN/datasets/horse2zebra/testB',
    #                                      help='Choose the type of images for domain Y.')

    parser.add_argument('--load_G_XtoY',
                        default='/home/manuelladron/projects/lbis_p/attention-based_image_translation/cyclegan'
                                '/checkpoints_cyclegan/h2z_128/_10deluxe_instance_dc_mix_patch_4_blocks_9_width_512_perc_0.0005'
                                '/G_XtoY_iter20000.pkl')

    parser.add_argument('--load_G_YtoX',
                        default='/home/manuelladron/projects/lbis_p/attention-based_image_translation/cyclegan'
                                '/checkpoints_cyclegan/h2z_128/_10deluxe_instance_dc_mix_patch_4_blocks_9_width_512_perc_0.0005'
                                '/G_YtoX_iter20000.pkl')

    parser.add_argument('--ext', type=str, default='*.jpg', help='Choose the type of images for domain Y.')
    parser.add_argument('--data_aug', type=str, default='deluxe', help='basic / none/ deluxe')

    # Saving directories and checkpoint/sample iterations
    parser.add_argument('--sample_dir', type=str, default='cyclegan/h2z_128')
    parser.add_argument('--save_ind', type=bool, default=True, help='save individual pictures, without original pair')

    parser.add_argument('--gpu', type=str, default='0')
    parser.add_argument('--blocks', type=int, default=9)
    parser.add_argument('--patch', type=int, default=4)
    parser.add_argument('--test', type=bool, default=True)

    return parser

if __name__ == '__main__':
    parser = create_parser()
    opts = parser.parse_args()
    print(f"RUN: {vars(opts)}")

    if opts.save_ind:
        assert opts.batch_size == 1

    os.environ['CUDA_VISIBLE_DEVICES'] = opts.gpu
    opts.sample_dir = os.path.join('output/', opts.sample_dir,
                                   '%s_' % (opts.X.split('/')[0]))
    if opts.save_ind:
        opts.sample_dir += f'test_set_ind_width_{opts.g_conv_dim}_perc0.0005_bestCycleGAN'
        # X to Y Follows naming order of the dataset -> Apple to Orange, Horse 2 Zebra, Summer 2 Winter etc.
        opts.x2y_dir = opts.sample_dir + '_x2y'
        opts.y2x_dir = opts.sample_dir + '_y2x'

        opts.reals_dir = opts.sample_dir + f'_reals_all'
        opts.reals_x_dir = opts.sample_dir + f'_reals_x'
        opts.reals_y_dir = opts.sample_dir + f'_reals_y'

    else:
        opts.sample_dir += f'test_set_batch_{opts.batch_size}_width_{opts.g_conv_dim}_perc0.0005_bestCycleGAN'
    
    opts.patch_dim = (opts.image_size // opts.patch // 4) ** 2

    if os.path.exists(opts.sample_dir):
        cmd = 'rm %s/*' % opts.sample_dir
        os.system(cmd)

    if os.path.exists(opts.reals_dir):
        cmd = 'rm %s/*' % opts.reals_dir
        os.system(cmd)

    if os.path.exists(opts.reals_x_dir):
        cmd = 'rm %s/*' % opts.reals_x_dir
        os.system(cmd)

    if os.path.exists(opts.reals_y_dir):
        cmd = 'rm %s/*' % opts.reals_y_dir
        os.system(cmd)

    logger = SummaryWriter(opts.sample_dir)

    print_opts(opts)
    main(opts)